{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.MORDM OPTIMIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Generate random policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ema_workbench import load_results\n",
    "from ema_workbench import Scenario\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario)\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "import time\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, EpsilonProgress)\n",
    "from ema_workbench import Constraint\n",
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the basecase results\n",
    "experiments, outcomes = load_results('../results/basecase_results.tar.gz') \n",
    "outcomes_df = pd.DataFrame.from_dict(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Series which defines which are the experiments within the established threshold in the first part\n",
    "y3 = pd.read_csv('../results/boolean_worst_scenarios.csv').iloc[:, 1:]\n",
    "\n",
    "# Convert Series to a list\n",
    "y = np.array(y3).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out experiments which obey the established threshold\n",
    "experiments_of_interest = experiments.loc[y]\n",
    "outcomes_df = pd.DataFrame({k:v[y] for k,v in outcomes.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to aggregate over time and locations\n",
    "def aggregate_df(df):\n",
    "    df_aggregate_time = pd.DataFrame()\n",
    "    df_aggregate_time_location = pd.DataFrame()\n",
    "    locations = ['A.1', 'A.2', 'A.3', 'A.4', 'A.5']\n",
    "    step = ['0', '1', '2']\n",
    "    metrics = ['Expected Annual Damage', 'Dike Investment Costs', 'Expected Number of Deaths', 'RfR Total Costs', 'Expected Evacuation Costs']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric == \"RfR Total Costs\" or metric == \"Expected Evacuation Costs\":\n",
    "\n",
    "            columns = [metric + ' ' + time for time in step]\n",
    "\n",
    "            df_aggregate_time_location[metric + ' time aggregate'] = df[columns].sum(axis=1)\n",
    "        else:\n",
    "            for location in locations:\n",
    "                columns = [location + '_' + metric + ' ' + time for time in step]\n",
    "\n",
    "                df_aggregate_time[location + '_' + metric + ' time aggregate'] = df[columns].sum(axis=1)\n",
    "            \n",
    "            columns_locations = [location + '_' + metric + ' time aggregate' for location in locations]\n",
    "            df_aggregate_time_location[metric + ' time location aggregate'] = df_aggregate_time[columns_locations].sum(axis=1)\n",
    "                    \n",
    "\n",
    "    return df_aggregate_time, df_aggregate_time_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the outcome values\n",
    "df_agg_t, df_agg_tl = aggregate_df(outcomes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we want to select the worst case scnearios in order to optimize over them. For this, we rank all the different columns in the outcomes dataframe from highesto to lowest value. Then, we sum up the rank number and chose the scenarios which have the highest rank, i.e. the ones that perform the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that we're ranking on the base case, the dike investment costs are zero. Therfore, we drop those columns\n",
    "dike_inv = ['A.1_Dike Investment Costs time aggregate', 'A.2_Dike Investment Costs time aggregate', \n",
    "            'A.3_Dike Investment Costs time aggregate', 'A.4_Dike Investment Costs time aggregate', 'A.5_Dike Investment Costs time aggregate']\n",
    "\n",
    "df_agg_t.drop(columns=dike_inv, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rank each column and sum over each row value to obtain the rank of each scenario\n",
    "rank_df = pd.DataFrame()\n",
    "for column in df_agg_t.columns:\n",
    "    rank_df[column] = df_agg_t[column].rank()\n",
    "\n",
    "rank_df['Final rank'] = rank_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to sort out the values for the top 5 worst scenarios, we retrieve their index to then filter them out from the experiments \n",
    "worst_5_df = rank_df.sort_values(by='Final rank',ascending=False).head()\n",
    "worst_5_ind = list(worst_5_df.index)\n",
    "\n",
    "# Finally, we filter the worst scenarios out and only get back the first 19 columns, which correspond to the uncertainty values in each scenario\n",
    "scenarios_df = experiments_of_interest.iloc[worst_5_ind,:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the values of the uncertainties that correspond to the top 5 worst case scenarios, we specify them in the workbench and perform Multi-Scenario MORDM. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the scenarios in the workbench\n",
    "scenarios = [Scenario(f\"{index}\", **row) for index, row in scenarios_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the maximum and minimum values found across performing experiments for 100 policies across 400 scenarios\n",
    "import pickle\n",
    "with open('../results/min_max_range_basecase.pickle', 'rb') as f:\n",
    "    max_range_bc, min_range_bc = pickle.load(f)\n",
    "with open('../results/min_max_range_randompolicies.pickle', 'rb') as f:\n",
    "    max_range_rp, min_range_rp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range = pd.concat([max_range_bc, max_range_rp], axis=1)\n",
    "min_range = pd.concat([min_range_bc, min_range_rp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range = max_range.max(axis=1)\n",
    "min_range = min_range.min(axis=1)\n",
    "max_range.drop(labels=['RfR Total Costs time aggregate'], inplace=True)\n",
    "min_range.drop(labels=['RfR Total Costs time aggregate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expected Annual Damage time location aggregate       6.790428e+09\n",
       "Dike Investment Costs time location aggregate        9.334020e+08\n",
       "Expected Number of Deaths time location aggregate    5.855678e+00\n",
       "Expected Evacuation Costs time aggregate             1.246373e+05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "\n",
    "def sum_over(*args):\n",
    "    return sum(args)\n",
    "\n",
    "def get_model_for_problem_formulation_altered(min_range, max_range):\n",
    "    ''' Prepare DikeNetwork in a way it can be input in the EMA-workbench.\n",
    "    Specify uncertainties, levers and problem formulation.\n",
    "    \n",
    "    We only consider what is originally labelled as problem formulation 2, but without Rfr costs as an outcome. \n",
    "    Additionally, we incorpare the ranges across which we consider the outcomes to be within.\n",
    "    '''\n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    dike_model = Model('dikesnet', function=function)\n",
    "\n",
    "    # Uncertainties and Levers:\n",
    "    # Specify uncertainties range:\n",
    "    Real_uncert = {'Bmax': [30, 350], 'pfail': [0, 1]}  # m and [.]\n",
    "    # breach growth rate [m/day]\n",
    "    cat_uncert_loc = {'Brate': (1., 1.5, 10)}\n",
    "\n",
    "    cat_uncert = {'discount rate {}'.format(n): (1.5, 2.5, 3.5, 4.5)\n",
    "                    for n in function.planning_steps}\n",
    "    \n",
    "    Int_uncert = {'A.0_ID flood wave shape': [0, 132]}\n",
    "    # Range of dike heightening:\n",
    "    dike_lev = {'DikeIncrease': [0, 10]}    # dm\n",
    "\n",
    "    # Series of five Room for the River projects:\n",
    "    rfr_lev = ['{}_RfR'.format(project_id) for project_id in range(0, 5)]\n",
    "\n",
    "    # Time of warning: 0, 1, 2, 3, 4 days ahead from the flood\n",
    "    EWS_lev = {'EWS_DaysToThreat': [0, 4]}  # days\n",
    "\n",
    "    uncertainties = []\n",
    "    levers = []\n",
    "\n",
    "    for uncert_name in cat_uncert.keys():\n",
    "        categories = cat_uncert[uncert_name]\n",
    "        uncertainties.append(CategoricalParameter(uncert_name, categories))\n",
    "\n",
    "    for uncert_name in Int_uncert.keys():\n",
    "        uncertainties.append(IntegerParameter(uncert_name, \n",
    "                                              Int_uncert[uncert_name][0],\n",
    "                                              Int_uncert[uncert_name][1]))    \n",
    "\n",
    "    # RfR levers can be either 0 (not implemented) or 1 (implemented)\n",
    "    for lev_name in rfr_lev:\n",
    "        for n in function.planning_steps:\n",
    "            lev_name_ = '{} {}'.format(lev_name, n)\n",
    "            levers.append(IntegerParameter(lev_name_, 0, 1))\n",
    "\n",
    "    # Early Warning System lever\n",
    "    for lev_name in EWS_lev.keys():\n",
    "        levers.append(IntegerParameter(lev_name, EWS_lev[lev_name][0],\n",
    "                                       EWS_lev[lev_name][1]))\n",
    "    \n",
    "    for dike in function.dikelist:\n",
    "        # uncertainties in the form: locationName_uncertaintyName\n",
    "        for uncert_name in Real_uncert.keys():\n",
    "            name = \"{}_{}\".format(dike, uncert_name)\n",
    "            lower, upper = Real_uncert[uncert_name]\n",
    "            uncertainties.append(RealParameter(name, lower, upper))\n",
    "\n",
    "        for uncert_name in cat_uncert_loc.keys():\n",
    "            name = \"{}_{}\".format(dike, uncert_name)\n",
    "            categories = cat_uncert_loc[uncert_name]\n",
    "            uncertainties.append(CategoricalParameter(name, categories))\n",
    "\n",
    "        # location-related levers in the form: locationName_leversName\n",
    "        for lev_name in dike_lev.keys():\n",
    "            for n in function.planning_steps:\n",
    "                name = \"{}_{} {}\".format(dike, lev_name, n)\n",
    "                levers.append(IntegerParameter(name, dike_lev[lev_name][0],\n",
    "                                           dike_lev[lev_name][1]))\n",
    "\n",
    "    # load uncertainties and levers in dike_model:\n",
    "    dike_model.uncertainties = uncertainties\n",
    "    dike_model.levers = levers\n",
    "\n",
    "    # Problem formulations:\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "\n",
    "    variable_names = []\n",
    "    variable_names_ = []\n",
    "    variable_names__ = []        \n",
    "    variable_names___ = []\n",
    "    variable_names____ = []\n",
    "\n",
    "    for n in function.planning_steps:\n",
    "        variable_names.extend(['{}_Expected Annual Damage {}'.format(dike, n)\n",
    "                                     for dike in function.dikelist])\n",
    "        variable_names_.extend(['{}_Dike Investment Costs {}'.format(dike, n)\n",
    "                                  for dike in function.dikelist])\n",
    "        variable_names__.extend(['RfR Total Costs {}'.format(n)])       \n",
    "        variable_names___.extend(['Expected Evacuation Costs {}'.format(n)])\n",
    "        variable_names____.extend(['{}_Expected Number of Deaths {}'.format(dike, n)\n",
    "                                     for dike in function.dikelist])\n",
    "\n",
    "    dike_model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage',\n",
    "                      variable_name=[var for var in variable_names],\n",
    "                      function=sum_over, kind=direction, expected_range=(min_range[max_range.index[0]], max_range[max_range.index[0]])),\n",
    "\n",
    "            ScalarOutcome('Dike Investment Costs',\n",
    "                      variable_name=[var for var in variable_names_],\n",
    "                      function=sum_over, kind=direction, expected_range=(min_range[max_range.index[1]], max_range[max_range.index[1]])),\n",
    "\n",
    "            ScalarOutcome('Evacuation Costs',\n",
    "                      variable_name=[var for var in variable_names___],\n",
    "                      function=sum_over, kind=direction, expected_range=(min_range[max_range.index[3]], max_range[max_range.index[3]])),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths',\n",
    "                      variable_name=[var for var in variable_names____],\n",
    "                      function=sum_over, kind=direction, expected_range=(min_range[max_range.index[2]], max_range[max_range.index[2]]))]\n",
    "        \n",
    "    return dike_model, function.planning_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dike_model, planning_steps = get_model_for_problem_formulation_altered(2)\n",
    "\n",
    "# annual_dmg_var = ['A.1_Expected Annual Damage 0', 'A.1_Expected Annual Damage 1', 'A.1_Expected Annual Damage 2',\n",
    "#                    'A.2_Expected Annual Damage 0', 'A.2_Expected Annual Damage 1', 'A.2_Expected Annual Damage 2',\n",
    "#                    'A.3_Expected Annual Damage 0', 'A.3_Expected Annual Damage 1', 'A.3_Expected Annual Damage 2',\n",
    "#                    'A.4_Expected Annual Damage 0', 'A.4_Expected Annual Damage 1', 'A.4_Expected Annual Damage 2',\n",
    "#                    'A.5_Expected Annual Damage 0', 'A.5_Expected Annual Damage 1', 'A.5_Expected Annual Damage 2']\n",
    "\n",
    "# deaths_var = ['A.1_Expected Number of Deaths 0', 'A.1_Expected Number of Deaths 1', 'A.1_Expected Number of Deaths 2',\n",
    "#                    'A.2_Expected Number of Deaths 0', 'A.2_Expected Number of Deaths 1', 'A.2_Expected Number of Deaths 2',\n",
    "#                    'A.3_Expected Number of Deaths 0', 'A.3_Expected Number of Deaths 1', 'A.3_Expected Number of Deaths 2',\n",
    "#                    'A.4_Expected Number of Deaths 0', 'A.4_Expected Number of Deaths 1', 'A.4_Expected Number of Deaths 2',\n",
    "#                    'A.5_Expected Number of Deaths 0', 'A.5_Expected Number of Deaths 1', 'A.5_Expected Number of Deaths 2']\n",
    "\n",
    "# dikes_var= ['A.1_Dike Investment Costs 0', 'A.1_Dike Investment Costs 1', 'A.1_Dike Investment Costs 2',\n",
    "#                  'A.2_Dike Investment Costs 0', 'A.2_Dike Investment Costs 1', 'A.2_Dike Investment Costs 2',\n",
    "#                  'A.3_Dike Investment Costs 0', 'A.3_Dike Investment Costs 1', 'A.3_Dike Investment Costs 2',\n",
    "#                  'A.4_Dike Investment Costs 0', 'A.4_Dike Investment Costs 1', 'A.4_Dike Investment Costs 2',\n",
    "#                  'A.5_Dike Investment Costs 0', 'A.5_Dike Investment Costs 1', 'A.5_Dike Investment Costs 2']\n",
    "\n",
    "# rfr_costs_var = ['RfR Total Costs 0', 'RfR Total Costs 1', 'RfR Total Costs 2']\n",
    "\n",
    "# evac_costs_var = ['Expected Evacuation Costs 0','Expected Evacuation Costs 1', 'Expected Evacuation Costs 2']\n",
    "\n",
    "\n",
    "# dike_model.outcomes = [ScalarOutcome('Expected Annual Damage', variable_name=annual_dmg_var, kind=ScalarOutcome.MINIMIZE, function=sum_over,\n",
    "#                                      expected_range=(min_range[max_range.index[0]], max_range[max_range.index[0]])),\n",
    "#                        ScalarOutcome('Dike Investment Costs', variable_name=dikes_var, kind=ScalarOutcome.MINIMIZE, function=sum_over,\n",
    "#                                      expected_range=(min_range[max_range.index[1]], max_range[max_range.index[1]])),\n",
    "#                        ScalarOutcome('Evacuation Costs', variable_name=evac_costs_var, kind=ScalarOutcome.MINIMIZE, function=sum_over,\n",
    "#                                     expected_range=(min_range[max_range.index[3]], max_range[max_range.index[3]])),\n",
    "#                        ScalarOutcome('Expected Number of Deaths', variable_name=deaths_var, kind=ScalarOutcome.MINIMIZE, function=sum_over,\n",
    "#                                     expected_range=(min_range[max_range.index[2]], max_range[max_range.index[2]]))]\n",
    "\n",
    "\n",
    "# Initialise the altered formulation\n",
    "dike_model, planning_steps = get_model_for_problem_formulation_altered(min_range,max_range)\n",
    "\n",
    "\n",
    "deaths = ['Expected Number of Deaths']\n",
    "\n",
    "max_num_deaths = 0.00001\n",
    "\n",
    "# Adding the constraint for Room for the total number of deaths.\n",
    "constraints = [Constraint(\"Max number of deaths\", outcome_names=deaths,\n",
    "                          function=lambda x:max(0, x-max_num_deaths))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalarOutcome('Expected Annual Damage', variable_name=['A.1_Expected Annual Damage 0', 'A.2_Expected Annual Damage 0', 'A.3_Expected Annual Damage 0', 'A.4_Expected Annual Damage 0', 'A.5_Expected Annual Damage 0', 'A.1_Expected Annual Damage 1', 'A.2_Expected Annual Damage 1', 'A.3_Expected Annual Damage 1', 'A.4_Expected Annual Damage 1', 'A.5_Expected Annual Damage 1', 'A.1_Expected Annual Damage 2', 'A.2_Expected Annual Damage 2', 'A.3_Expected Annual Damage 2', 'A.4_Expected Annual Damage 2', 'A.5_Expected Annual Damage 2'], function=<function sum_over at 0x000001A8611A2E58>)\n",
      "ScalarOutcome('Dike Investment Costs', variable_name=['A.1_Dike Investment Costs 0', 'A.2_Dike Investment Costs 0', 'A.3_Dike Investment Costs 0', 'A.4_Dike Investment Costs 0', 'A.5_Dike Investment Costs 0', 'A.1_Dike Investment Costs 1', 'A.2_Dike Investment Costs 1', 'A.3_Dike Investment Costs 1', 'A.4_Dike Investment Costs 1', 'A.5_Dike Investment Costs 1', 'A.1_Dike Investment Costs 2', 'A.2_Dike Investment Costs 2', 'A.3_Dike Investment Costs 2', 'A.4_Dike Investment Costs 2', 'A.5_Dike Investment Costs 2'], function=<function sum_over at 0x000001A8611A2E58>)\n",
      "ScalarOutcome('Evacuation Costs', variable_name=['Expected Evacuation Costs 0', 'Expected Evacuation Costs 1', 'Expected Evacuation Costs 2'], function=<function sum_over at 0x000001A8611A2E58>)\n",
      "ScalarOutcome('Expected Number of Deaths', variable_name=['A.1_Expected Number of Deaths 0', 'A.2_Expected Number of Deaths 0', 'A.3_Expected Number of Deaths 0', 'A.4_Expected Number of Deaths 0', 'A.5_Expected Number of Deaths 0', 'A.1_Expected Number of Deaths 1', 'A.2_Expected Number of Deaths 1', 'A.3_Expected Number of Deaths 1', 'A.4_Expected Number of Deaths 1', 'A.5_Expected Number of Deaths 1', 'A.1_Expected Number of Deaths 2', 'A.2_Expected Number of Deaths 2', 'A.3_Expected Number of Deaths 2', 'A.4_Expected Number of Deaths 2', 'A.5_Expected Number of Deaths 2'], function=<function sum_over at 0x000001A8611A2E58>)\n"
     ]
    }
   ],
   "source": [
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] generation 0: 0/1 nfe\n"
     ]
    }
   ],
   "source": [
    "# perform the analysis\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, EpsilonProgress)\n",
    "from ema_workbench import Constraint\n",
    "\n",
    "convergence_metrics = [HyperVolume.from_outcomes(dike_model.outcomes),\n",
    "                       EpsilonProgress()]\n",
    "\n",
    "nfe = 1 \n",
    "results_deep = []\n",
    "convergence_all = []\n",
    "\n",
    "\n",
    "#We define the epsilons as a 100th part of the maximum value of the outcome\n",
    "for scenario in scenarios:\n",
    "    with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results_runs, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "                                        epsilons=[1e7, 1e6, 1e3, 0.01],\n",
    "                                        convergence=convergence_metrics, reference=scenario,\n",
    "                                        constraints=constraints)\n",
    "                                        \n",
    "        \n",
    "        results_deep.append(results_runs)\n",
    "        convergence_all.append(convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == SMALLER:\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "SMALLER = 'SMALLER'\n",
    "\n",
    "Expected_Number_of_Deaths = functools.partial(robustness, SMALLER, 0.000001) #not ok\n",
    "Expected_Annual_Damage = functools.partial(robustness, SMALLER, 1000) #THOSE NUMBERS NEED TO BE SPECIFIED AGAINS\n",
    "Total_Investment_Costs = functools.partial(robustness, SMALLER, 150000000)#THOSE NUMBERS NEED TO BE SPECIFIED AGAINS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "model = get_model_for_problem_formulation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import ema_logging, MultiprocessingEvaluator\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=200,               #500\n",
    "                                            policies=4,\n",
    "                                            uncertainty_sampling='mc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8,8),\n",
    "                        sharex=True)\n",
    "axes = [axes[0,0],axes[0,1],axes[1,0],axes[1,1]]                             #axes[1,1]\n",
    "\n",
    "robustness_funcs = {\"Expected Number of Deaths\": Expected_Number_of_Deaths,\n",
    "                    \"Expected Annual Damage\": Expected_Annual_Damage,\n",
    "                    \"Total Investment Costs\": Total_Investment_Costs}\n",
    "\n",
    "experiments, outcomes = results\n",
    "\n",
    "for ax, (outcome, value) in zip(axes, outcomes.items()):\n",
    "    for policy in np.unique(experiments['policy']):\n",
    "        logical = experiments['policy'] == policy\n",
    "        data = value[logical]\n",
    "        \n",
    "        robustness = []\n",
    "      \n",
    "        for i in range(1, data.shape[0]):\n",
    "            robustness.append(robustness_funcs[outcome](data[0:i]))\n",
    "        ax.plot(robustness, label=policy)\n",
    "    ax.set_xlabel(\"# experiments\")\n",
    "    ax.set_ylabel(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Search for candidate solutions\n",
    "\n",
    "the fundamental problem is fine tuning the robustness functions. To do this, rather than run optimizaitons many times, why not first generate a test set with a bunch of policies, apply robustness functions and visualize the results?\n",
    "\n",
    "This gives us much faster feedback on reasonble cutoff values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework import sample_uncertainties\n",
    "n_scenarios = 10\n",
    "scenarios = sample_uncertainties(model, n_scenarios)\n",
    "nfe = int(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios,              \n",
    "                                            policies=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(outcomes)\n",
    "data['policy'] = experiments['policy']\n",
    "sns.violinplot(data=data, y='Total Investment Costs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(outcomes)\n",
    "data['policy'] = experiments['policy']\n",
    "ax = sns.violinplot(data=data, y='Expected Annual Damage')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(outcomes)\n",
    "data['policy'] = experiments['policy']\n",
    "ax = sns.violinplot(data=data, y='Expected Number of Deaths')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == SMALLER:\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "SMALLER = 'SMALLER'\n",
    "\n",
    "Expected_Number_of_Deaths = functools.partial(robustness, SMALLER, 1e-5) #not ok\n",
    "Expected_Annual_Damage = functools.partial(robustness, SMALLER, 1e4) #THOSE NUMBERS NEED TO BE SPECIFIED AGAINS\n",
    "Total_Investment_Costs = functools.partial(robustness, SMALLER, 6e8)#THOSE NUMBERS NEED TO BE SPECIFIED AGAINS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "experiments, outcomes = results\n",
    "\n",
    "funcs = {'Expected Number of Deaths':Expected_Number_of_Deaths,\n",
    "         'Expected Annual Damage': Expected_Annual_Damage,\n",
    "         'Total Investment Costs': Total_Investment_Costs}\n",
    "\n",
    "total_scores = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    logical = experiments['policy'] == policy\n",
    "    \n",
    "    temp_outcomes = {k:v[logical] for k,v in outcomes.items()}\n",
    "    \n",
    "    for k, v in temp_outcomes.items():\n",
    "        score = funcs[k](v)\n",
    "        scores[k] = score\n",
    "    total_scores[policy] = scores\n",
    "\n",
    "data = pd.DataFrame(total_scores).T.reset_index(drop=True)\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, :] = 0\n",
    "limits.loc[1, :] = 1\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (MultiprocessingEvaluator, ema_logging, \n",
    "                           perform_experiments, SequentialEvaluator)\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, \n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "BaseEvaluator.reporting_frequency = 0.1\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# there is a bit of problem with platypus, so using 1.1. gives \n",
    "# cleaner hypervolume results.\n",
    "convergence = [HyperVolume(minimum=[0,0,0], maximum=[1.1, 1.1, 1.1]),\n",
    "              EpsilonProgress()]\n",
    "\n",
    "epsilons=[0.05,]*len(robustnes_functions)  #final value of epsilon should be much lower.Just for experiment purposes is 1\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    archive, convergence = evaluator.robust_optimize(robustnes_functions, scenarios,nfe=nfe,\n",
    "                                                     convergence=convergence, epsilons=epsilons)\n",
    "    \n",
    "#start = time.time()\n",
    "#end = time.time()\n",
    "\n",
    "#print('Processing time:',(end-start)/60,'Minutes')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "data = archive.loc[:, [o.name for o in robustnes_functions]]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, :] = 0\n",
    "limits.loc[1, :] = 1\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit better but not much. \n",
    "\n",
    "Now, observe the following: you are using a domain criterion as your sole measure of robustness. That is, you look at the fraction of scenarios above or below a threshold. The costs however do not vary accross scenarios. Thus this objective can only be 0 or 1. This is not particularly useful for optimization. \n",
    "\n",
    "We might thus want to consider another metric for costs. Why not simply use the raw costs itself?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == SMALLER:\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "def costs(data):\n",
    "    return data[0]/1e9 # makes numbers nicer\n",
    "    \n",
    "SMALLER = 'SMALLER'\n",
    "\n",
    "Expected_Number_of_Deaths = functools.partial(robustness, SMALLER, 1e-5) #not ok\n",
    "Expected_Annual_Damage = functools.partial(robustness, SMALLER, 1e4) #THOSE NUMBERS NEED TO BE SPECIFIED AGAINS\n",
    "Total_Investment_Costs = costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "experiments, outcomes = results\n",
    "\n",
    "funcs = {'Expected Number of Deaths':Expected_Number_of_Deaths,\n",
    "         'Expected Annual Damage': Expected_Annual_Damage,\n",
    "         'Total Investment Costs': Total_Investment_Costs}\n",
    "\n",
    "total_scores = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    logical = experiments['policy'] == policy\n",
    "    \n",
    "    temp_outcomes = {k:v[logical] for k,v in outcomes.items()}\n",
    "    \n",
    "    for k, v in temp_outcomes.items():\n",
    "        score = funcs[k](v)\n",
    "        scores[k] = score\n",
    "    total_scores[policy] = scores\n",
    "\n",
    "data = pd.DataFrame(total_scores).T.reset_index(drop=True)\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, :] = 0\n",
    "limits.loc[1, :] = 1\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already looks much nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXIMIZE = ScalarOutcome.MAXIMIZE\n",
    "MINIMIZE = ScalarOutcome.MINIMIZE\n",
    "\n",
    "funcs = {'Expected Number of Deaths':Expected_Number_of_Deaths,\n",
    "         'Expected Annual Damage': Expected_Annual_Damage,\n",
    "         'Total Investment Costs': Total_Investment_Costs}\n",
    "\n",
    "robustnes_functions = [ScalarOutcome('fraction EA deaths', kind=MAXIMIZE, \n",
    "                             variable_name='Expected Number of Deaths', function=Expected_Number_of_Deaths),\n",
    "                       ScalarOutcome('fraction EA damage', kind=MAXIMIZE, \n",
    "                             variable_name='Expected Annual Damage', function=Expected_Annual_Damage),\n",
    "                       ScalarOutcome('investment costs', kind=MINIMIZE, # note that we have to minimize costs!\n",
    "                             variable_name='Total Investment Costs', function=Total_Investment_Costs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to change the plausible max for total investment costs\n",
    "convergence = [HyperVolume(minimum=[0,0,0], maximum=[1.1, 1.1, 3]),\n",
    "              EpsilonProgress()]\n",
    "\n",
    "epsilons=[0.05,]*len(robustnes_functions)  #final value of epsilon should be much lower.Just for experiment purposes is 1\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    archive, convergence = evaluator.robust_optimize(robustnes_functions, scenarios, nfe=nfe,\n",
    "                                                     convergence=convergence, epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = archive.loc[:, [o.name for o in robustnes_functions]]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, :] = 0\n",
    "limits.loc[1, :] = 1\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Re-evaluate candidate solutions under uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Policy\n",
    "\n",
    "policies = archive.drop([o.name for o in robustnes_functions], axis=1)\n",
    "policies_to_evaluate = []\n",
    "\n",
    "for i, policy in policies.iterrows():\n",
    "    policies_to_evaluate.append(Policy(\"moro {}\".format(i), **policy.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_scenarios = 1000\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            policies_to_evaluate)\n",
    "\n",
    "#start = time.time()\n",
    "#end = time.time()\n",
    "\n",
    "#print('Processing time:',(end-start)/60,'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import save_results\n",
    "\n",
    "save_results(results, 'MORO_reevaluation.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies.to_csv('moro polices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "experiments, outcomes = results\n",
    "\n",
    "overall_robustness = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    policy_robustness = {}\n",
    "\n",
    "    logical = experiments['policy'] == policy\n",
    "    \n",
    "    for outcome, values in outcomes.items():\n",
    "        values = values[logical]\n",
    "        policy_robustness[outcome] = robustness_funcs[outcome](values)\n",
    "    overall_robustness[policy] = policy_robustness\n",
    "overall_robustness = pd.DataFrame.from_dict(overall_robustness).T\n",
    "overall_robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = overall_robustness.loc[:, \n",
    "                              ['Expected Number of Deaths', 'Expected Annual Damage', 'Total Investment Costs']]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, :] = 0\n",
    "limits.loc[1, :] = 1\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
