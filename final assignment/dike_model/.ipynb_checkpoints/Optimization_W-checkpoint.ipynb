{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.4\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "# make sure pandas is version 1.0 or higher\n",
    "# make sure networkx is verion 2.4 or higher\n",
    "print(pd.__version__)\n",
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "\n",
    "\n",
    "def sum_over(*args):\n",
    "    return sum(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "import time\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "#choose problem formulation number, between 0-5\n",
    "#each problem formulation has its own list of outcomes\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalParameter('discount rate 0', [0, 1, 2, 3])\n",
      "CategoricalParameter('discount rate 1', [0, 1, 2, 3])\n",
      "CategoricalParameter('discount rate 2', [0, 1, 2, 3])\n",
      "IntegerParameter('A.0_ID flood wave shape', 0, 132)\n",
      "RealParameter('A.1_Bmax', 30, 350)\n",
      "RealParameter('A.1_pfail', 0, 1)\n",
      "CategoricalParameter('A.1_Brate', [0, 1, 2])\n",
      "RealParameter('A.2_Bmax', 30, 350)\n",
      "RealParameter('A.2_pfail', 0, 1)\n",
      "CategoricalParameter('A.2_Brate', [0, 1, 2])\n",
      "RealParameter('A.3_Bmax', 30, 350)\n",
      "RealParameter('A.3_pfail', 0, 1)\n",
      "CategoricalParameter('A.3_Brate', [0, 1, 2])\n",
      "RealParameter('A.4_Bmax', 30, 350)\n",
      "RealParameter('A.4_pfail', 0, 1)\n",
      "CategoricalParameter('A.4_Brate', [0, 1, 2])\n",
      "RealParameter('A.5_Bmax', 30, 350)\n",
      "RealParameter('A.5_pfail', 0, 1)\n",
      "CategoricalParameter('A.5_Brate', [0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "#enlisting uncertainties, their types (RealParameter/IntegerParameter/CategoricalParameter), lower boundary, and upper boundary\n",
    "for unc in dike_model.uncertainties:\n",
    "    print(repr(unc))\n",
    "    \n",
    "uncertainties = dike_model.uncertainties\n",
    "\n",
    "import copy\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntegerParameter('0_RfR 0', 0, 1)\n",
      "IntegerParameter('0_RfR 1', 0, 1)\n",
      "IntegerParameter('0_RfR 2', 0, 1)\n",
      "IntegerParameter('1_RfR 0', 0, 1)\n",
      "IntegerParameter('1_RfR 1', 0, 1)\n",
      "IntegerParameter('1_RfR 2', 0, 1)\n",
      "IntegerParameter('2_RfR 0', 0, 1)\n",
      "IntegerParameter('2_RfR 1', 0, 1)\n",
      "IntegerParameter('2_RfR 2', 0, 1)\n",
      "IntegerParameter('3_RfR 0', 0, 1)\n",
      "IntegerParameter('3_RfR 1', 0, 1)\n",
      "IntegerParameter('3_RfR 2', 0, 1)\n",
      "IntegerParameter('4_RfR 0', 0, 1)\n",
      "IntegerParameter('4_RfR 1', 0, 1)\n",
      "IntegerParameter('4_RfR 2', 0, 1)\n",
      "IntegerParameter('EWS_DaysToThreat', 0, 4)\n",
      "IntegerParameter('A.1_DikeIncrease 0', 0, 10)\n",
      "IntegerParameter('A.1_DikeIncrease 1', 0, 10)\n",
      "IntegerParameter('A.1_DikeIncrease 2', 0, 10)\n",
      "IntegerParameter('A.2_DikeIncrease 0', 0, 10)\n",
      "IntegerParameter('A.2_DikeIncrease 1', 0, 10)\n",
      "IntegerParameter('A.2_DikeIncrease 2', 0, 10)\n",
      "IntegerParameter('A.3_DikeIncrease 0', 0, 10)\n",
      "IntegerParameter('A.3_DikeIncrease 1', 0, 10)\n",
      "IntegerParameter('A.3_DikeIncrease 2', 0, 10)\n",
      "IntegerParameter('A.4_DikeIncrease 0', 0, 10)\n",
      "IntegerParameter('A.4_DikeIncrease 1', 0, 10)\n",
      "IntegerParameter('A.4_DikeIncrease 2', 0, 10)\n",
      "IntegerParameter('A.5_DikeIncrease 0', 0, 10)\n",
      "IntegerParameter('A.5_DikeIncrease 1', 0, 10)\n",
      "IntegerParameter('A.5_DikeIncrease 2', 0, 10)\n"
     ]
    }
   ],
   "source": [
    "#enlisting policy levers, their types (RealParameter/IntegerParameter), lower boundary, and upper boundary\n",
    "for policy in dike_model.levers:\n",
    "    print(repr(policy))\n",
    "    \n",
    "levers = dike_model.levers \n",
    "\n",
    "import copy\n",
    "levers = copy.deepcopy(dike_model.levers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalarOutcome('A.1 Total Costs', variable_name=['A.1_Expected Annual Damage 0', 'A.1_Expected Annual Damage 1', 'A.1_Expected Annual Damage 2', 'A.1_Dike Investment Costs 0', 'A.1_Dike Investment Costs 1', 'A.1_Dike Investment Costs 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.1_Expected Number of Deaths', variable_name=['A.1_Expected Number of Deaths 0', 'A.1_Expected Number of Deaths 1', 'A.1_Expected Number of Deaths 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.2 Total Costs', variable_name=['A.2_Expected Annual Damage 0', 'A.2_Expected Annual Damage 1', 'A.2_Expected Annual Damage 2', 'A.2_Dike Investment Costs 0', 'A.2_Dike Investment Costs 1', 'A.2_Dike Investment Costs 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.2_Expected Number of Deaths', variable_name=['A.2_Expected Number of Deaths 0', 'A.2_Expected Number of Deaths 1', 'A.2_Expected Number of Deaths 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.3 Total Costs', variable_name=['A.3_Expected Annual Damage 0', 'A.3_Expected Annual Damage 1', 'A.3_Expected Annual Damage 2', 'A.3_Dike Investment Costs 0', 'A.3_Dike Investment Costs 1', 'A.3_Dike Investment Costs 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.3_Expected Number of Deaths', variable_name=['A.3_Expected Number of Deaths 0', 'A.3_Expected Number of Deaths 1', 'A.3_Expected Number of Deaths 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.4 Total Costs', variable_name=['A.4_Expected Annual Damage 0', 'A.4_Expected Annual Damage 1', 'A.4_Expected Annual Damage 2', 'A.4_Dike Investment Costs 0', 'A.4_Dike Investment Costs 1', 'A.4_Dike Investment Costs 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.4_Expected Number of Deaths', variable_name=['A.4_Expected Number of Deaths 0', 'A.4_Expected Number of Deaths 1', 'A.4_Expected Number of Deaths 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.5 Total Costs', variable_name=['A.5_Expected Annual Damage 0', 'A.5_Expected Annual Damage 1', 'A.5_Expected Annual Damage 2', 'A.5_Dike Investment Costs 0', 'A.5_Dike Investment Costs 1', 'A.5_Dike Investment Costs 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('A.5_Expected Number of Deaths', variable_name=['A.5_Expected Number of Deaths 0', 'A.5_Expected Number of Deaths 1', 'A.5_Expected Number of Deaths 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('RfR Total Costs', variable_name=['RfR Total Costs 0', 'RfR Total Costs 1', 'RfR Total Costs 2'], function=<function sum_over at 0x0000021D86328D38>)\n",
      "ScalarOutcome('Expected Evacuation Costs', variable_name=['Expected Evacuation Costs 0', 'Expected Evacuation Costs 1', 'Expected Evacuation Costs 2'], function=<function sum_over at 0x0000021D86328D38>)\n"
     ]
    }
   ],
   "source": [
    "#enlisting outcomes\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 5000 scenarios * 1 policies * 1 model(s) = 5000 experiments\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1500 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] 2500 cases completed\n",
      "[MainProcess/INFO] 3000 cases completed\n",
      "[MainProcess/INFO] 3500 cases completed\n",
      "[MainProcess/INFO] 4000 cases completed\n",
      "[MainProcess/INFO] 4500 cases completed\n",
      "[MainProcess/INFO] 5000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] results saved successfully to D:\\Willy\\Documents\\GitHub\\epa1361_open\\final assignment\\dike_5_results.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# policy_dict = {}\n",
    "# for i in range(5):\n",
    "#     for j in range(3):\n",
    "#         policy_dict[f'{i}_RfR {j}'] = 0\n",
    "# policy_dict['EWS_DaysToThreat'] = 0\n",
    "# for i in range(1,6):\n",
    "#     for j in range(3):\n",
    "#         policy_dict[f'A.{i}_DikeIncrease {j}'] = 5\n",
    "# policy_dict \n",
    "\n",
    "# policy = [Policy('only_rfr', **policy_dict)]\n",
    "\n",
    "# #pass the policies list to EMA workbench experiment runs\n",
    "# n_scenarios = 5000\n",
    "# with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "#     experiments, outcomes = evaluator.perform_experiments(n_scenarios,\n",
    "#                                             policy)\n",
    "\n",
    "# from ema_workbench.util import utilities\n",
    "# utilities.save_results((experiments, outcomes), 'dike_5_results.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Willy\\\\Documents\\\\GitHub\\\\epa1361_open\\\\results\\\\basecase_results.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-967b21f6cefd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load the basecase results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mema_workbench\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mexperiments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../results/basecase_results.tar.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\util\\utilities.py\u001b[0m in \u001b[0;36mload_results\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0moutcomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r:gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"UTF8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;31m# load x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mexperiments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'experiments.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unknown compression type %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1593\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m\"|\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Willy\\\\Documents\\\\GitHub\\\\epa1361_open\\\\results\\\\basecase_results.tar.gz'"
     ]
    }
   ],
   "source": [
    "# load the basecase results\n",
    "from ema_workbench import load_results\n",
    "experiments, outcomes = load_results('../results/basecase_results.tar.gz') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(3)\n",
    "\n",
    "# Redefine the uncertainties\n",
    "dike_model.uncertainties['A.1_pfail'] = RealParameter('A.1_pfail', 0.000120, 0.414252)\n",
    "dike_model.uncertainties['A.3_pfail'] = RealParameter('A.3_pfail', 0.000010, 0.181847)\n",
    "dike_model.uncertainties['A.1_Bmax'] = RealParameter('A.1_Bmax', 30.012525, 298.534935)\n",
    "#dike_model.uncertainties['A.4_Bmax'] = RealParameter('A.4_Bmax', 39.275594, 349.965209)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_to_n(*data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    return mean*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (MultiprocessingEvaluator, Policy, Scenario, Constraint)\n",
    "\n",
    "\n",
    "#Making lists of all the disaggregated variables in order to properly use the total aggregated variables\n",
    "\n",
    "#rfr_costs = ['RfR Total Costs 0', 'RfR Total Costs 1', 'RfR Total Costs 2']\n",
    "\n",
    "\n",
    "evac_costs = ['Expected Evacuation Costs']\n",
    "\n",
    "\n",
    "total_costs = ['A.1 Total Costs', 'A.2 Total Costs','A.3 Total Costs','A.4 Total Costs', 'A.5 Total Costs']\n",
    "\n",
    "#Specifying robustness functions. All have to be minimized. All except for the variance will use the 'signal_to_noise' function.\n",
    "#Variance will use the 'signal_to_noise_variation' function, which contains the extra step of first calculating the standard deviation.\n",
    "robustness_functions = [ScalarOutcome('Annual Costs Score', kind=ScalarOutcome.MINIMIZE, variable_name=total_costs, function=s_to_n),\n",
    "                        ScalarOutcome('Evacuation Costs Score', kind=ScalarOutcome.MINIMIZE, variable_name=evac_costs, function=s_to_n)]#,\n",
    "                        #ScalarOutcome('RfR Costs Score', kind=ScalarOutcome.MINIMIZE, variable_name=rfr_costs, function=s_to_n)]\n",
    "\n",
    "max_num_deaths = 0.00001\n",
    "\n",
    "# deaths = ['A.1_Expected Number of Deaths 0', 'A.1_Expected Number of Deaths 1', 'A.1_Expected Number of Deaths 2',\n",
    "#                    'A.2_Expected Number of Deaths 0', 'A.2_Expected Number of Deaths 1', 'A.2_Expected Number of Deaths 2',\n",
    "#                    'A.3_Expected Number of Deaths 0', 'A.3_Expected Number of Deaths 1', 'A.3_Expected Number of Deaths 2',\n",
    "#                    'A.4_Expected Number of Deaths 0', 'A.4_Expected Number of Deaths 1', 'A.4_Expected Number of Deaths 2',\n",
    "#                    'A.5_Expected Number of Deaths 0', 'A.5_Expected Number of Deaths 1', 'A.5_Expected Number of Deaths 2']\n",
    "\n",
    "deaths = ['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths','A.3_Expected Number of Deaths','A.4_Expected Number of Deaths','A.5_Expected Number of Deaths']\n",
    "\n",
    "#Adding the constraint for Room for the River costs.\n",
    "constraints = [Constraint(\"max number of deaths A.1\", outcome_names=deaths[0],\n",
    "                          function=lambda x:max(0, x-max_num_deaths)),\n",
    "               Constraint(\"max number of deaths A.2\", outcome_names=deaths[1],\n",
    "                          function=lambda x:max(0, x-max_num_deaths)),\n",
    "               Constraint(\"max number of deaths A.3\", outcome_names=deaths[2],\n",
    "                          function=lambda x:max(0, x-max_num_deaths)),\n",
    "               Constraint(\"max number of deaths A.4\", outcome_names=deaths[3],\n",
    "                          function=lambda x:max(0, x-max_num_deaths)),\n",
    "               Constraint(\"max number of deaths A.5\", outcome_names=deaths[4],\n",
    "                          function=lambda x:max(0, x-max_num_deaths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework import sample_uncertainties\n",
    "n_scenarios = 50\n",
    "scenarios = sample_uncertainties(dike_model, n_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] generation 0: 0/15000 nfe\n",
      "[MainProcess/INFO] generation 5: 498/15000 nfe\n",
      "[MainProcess/INFO] generation 10: 996/15000 nfe\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench.em_framework.optimization import (HyperVolume, \n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "import time\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "convergence = [HyperVolume(minimum=[1e10, 500000, 1e10, 1e2], \n",
    "                           maximum=[1e20, 1000000, 1e20, 1e10]),\n",
    "               EpsilonProgress()]\n",
    "nfe = int(15000)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    archive, convergence = evaluator.robust_optimize(robustness_functions, scenarios=n_scenarios, \n",
    "                                               nfe=nfe, convergence=convergence,\n",
    "                                               epsilons=[0.01,1000000000,100000,1000000000,10000],\n",
    "                                               constraint=constraints)\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Processing time:',(end-start)/60,'Minutes')\n",
    "\n",
    "from ema_workbench.util import utilities\n",
    "utilities.save_results((archive, convergence), 'optimisation_results.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
