{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.MORDM OPTIMIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Generate random policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ema_workbench import load_results\n",
    "from ema_workbench import Scenario\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario)\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "import time\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, EpsilonProgress)\n",
    "from ema_workbench import Constraint\n",
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario, SequentialEvaluator)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded succesfully from D:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\results\\mordm_7500_rp_scenario0.tar.gz\n",
      "[MainProcess/INFO] results loaded succesfully from D:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\results\\mordm_7500_rp_scenario1.tar.gz\n",
      "[MainProcess/INFO] results loaded succesfully from D:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\results\\mordm_7500_rp_scenario2.tar.gz\n",
      "[MainProcess/INFO] results loaded succesfully from D:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\results\\mordm_7500_rp_scenario3.tar.gz\n",
      "[MainProcess/INFO] results loaded succesfully from D:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\results\\mordm_7500_rp_scenario4.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench import load_results\n",
    "\n",
    "results_deep = []\n",
    "convergence_all = []\n",
    "\n",
    "for i in range(5):\n",
    "    result, convergence = load_results(f'../results/mordm_7500_rp_scenario{i}.tar.gz')\n",
    "    results_deep.append(result)\n",
    "    convergence_all.append(convergence)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_RfR 0</th>\n",
       "      <th>0_RfR 1</th>\n",
       "      <th>0_RfR 2</th>\n",
       "      <th>1_RfR 0</th>\n",
       "      <th>1_RfR 1</th>\n",
       "      <th>1_RfR 2</th>\n",
       "      <th>2_RfR 0</th>\n",
       "      <th>2_RfR 1</th>\n",
       "      <th>2_RfR 2</th>\n",
       "      <th>3_RfR 0</th>\n",
       "      <th>...</th>\n",
       "      <th>A.2_DikeIncrease 2</th>\n",
       "      <th>A.3_DikeIncrease 0</th>\n",
       "      <th>A.3_DikeIncrease 1</th>\n",
       "      <th>A.3_DikeIncrease 2</th>\n",
       "      <th>A.4_DikeIncrease 0</th>\n",
       "      <th>A.4_DikeIncrease 1</th>\n",
       "      <th>A.4_DikeIncrease 2</th>\n",
       "      <th>A.5_DikeIncrease 0</th>\n",
       "      <th>A.5_DikeIncrease 1</th>\n",
       "      <th>A.5_DikeIncrease 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_RfR 0  0_RfR 1  0_RfR 2  1_RfR 0  1_RfR 1  1_RfR 2  2_RfR 0  2_RfR 1  \\\n",
       "0        1        0        1        0        1        0        1        1   \n",
       "1        0        0        0        1        1        0        1        1   \n",
       "2        1        0        1        0        1        1        1        1   \n",
       "3        1        0        1        0        0        0        1        1   \n",
       "4        1        0        1        1        1        1        1        1   \n",
       "5        0        0        0        0        1        1        1        1   \n",
       "6        1        0        1        0        0        0        1        1   \n",
       "7        1        0        1        1        1        0        1        1   \n",
       "\n",
       "   2_RfR 2  3_RfR 0  ...  A.2_DikeIncrease 2  A.3_DikeIncrease 0  \\\n",
       "0        1        1  ...                   0                   3   \n",
       "1        1        1  ...                   0                   3   \n",
       "2        1        1  ...                   0                   3   \n",
       "3        1        1  ...                   0                   3   \n",
       "4        1        1  ...                   0                   3   \n",
       "5        1        1  ...                   0                   3   \n",
       "6        1        1  ...                   0                   3   \n",
       "7        1        1  ...                   0                   3   \n",
       "\n",
       "   A.3_DikeIncrease 1  A.3_DikeIncrease 2  A.4_DikeIncrease 0  \\\n",
       "0                   0                   0                   3   \n",
       "1                   0                   0                   2   \n",
       "2                   0                   0                   3   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   1   \n",
       "5                   0                   0                   2   \n",
       "6                   0                   0                   0   \n",
       "7                   0                   0                   1   \n",
       "\n",
       "   A.4_DikeIncrease 1  A.4_DikeIncrease 2  A.5_DikeIncrease 0  \\\n",
       "0                   0                   0                   4   \n",
       "1                   0                   0                   3   \n",
       "2                   0                   0                   3   \n",
       "3                   0                   0                   2   \n",
       "4                   0                   0                   3   \n",
       "5                   0                   0                   3   \n",
       "6                   0                   0                   2   \n",
       "7                   0                   0                   3   \n",
       "\n",
       "   A.5_DikeIncrease 1  A.5_DikeIncrease 2  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   0                   0  \n",
       "4                   0                   0  \n",
       "5                   0                   0  \n",
       "6                   0                   0  \n",
       "7                   0                   0  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, result in enumerate(results_deep):\n",
    "    outcomes_of_interest = result.iloc[:, :-3]\n",
    "outcomes_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Policy\n",
    "\n",
    "policies = []\n",
    "for i, result in enumerate(results_deep):\n",
    "    outcomes_of_interest = result.iloc[:, :-3]\n",
    "    for j, row in outcomes_of_interest.iterrows():\n",
    "        policy = Policy(f'scenario {i} policy {j}', **row.to_dict())\n",
    "        policies.append(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Policy({'0_RfR 0': 1, '0_RfR 1': 0, '0_RfR 2': 0, '1_RfR 0': 1, '1_RfR 1': 1, '1_RfR 2': 1, '2_RfR 0': 1, '2_RfR 1': 1, '2_RfR 2': 1, '3_RfR 0': 1, '3_RfR 1': 1, '3_RfR 2': 1, '4_RfR 0': 1, '4_RfR 1': 1, '4_RfR 2': 1, 'EWS_DaysToThreat': 3, 'A.1_DikeIncrease 0': 0, 'A.1_DikeIncrease 1': 0, 'A.1_DikeIncrease 2': 0, 'A.2_DikeIncrease 0': 4, 'A.2_DikeIncrease 1': 0, 'A.2_DikeIncrease 2': 0, 'A.3_DikeIncrease 0': 1, 'A.3_DikeIncrease 1': 0, 'A.3_DikeIncrease 2': 0, 'A.4_DikeIncrease 0': 1, 'A.4_DikeIncrease 1': 0, 'A.4_DikeIncrease 2': 0, 'A.5_DikeIncrease 0': 8, 'A.5_DikeIncrease 1': 0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "# We use the original problem formulation to account for the RfR policies\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 1000 scenarios * 42 policies * 1 model(s) = 42000 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/ERROR] 'DikeIncrease 2'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py\", line 85, in run_experiment\n",
      "    model.run_model(scenario, policy)\n",
      "  File \"C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\", line 158, in wrapper\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\", line 338, in run_model\n",
      "    outputs = self.run_experiment(experiment)\n",
      "  File \"C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\", line 158, in wrapper\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\", line 391, in run_experiment\n",
      "    model_output = self.function(**experiment)\n",
      "  File \"D:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\dike_model\\dike_model_function.py\", line 158, in __call__\n",
      "    self.progressive_height_and_costs(G, dikelist, self.planning_steps)\n",
      "  File \"D:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\dike_model\\dike_model_function.py\", line 94, in progressive_height_and_costs\n",
      "    node['DikeIncrease {}'.format(s)] *= self.dh\n",
      "KeyError: 'DikeIncrease 2'\n"
     ]
    },
    {
     "ename": "EMAError",
     "evalue": "exception in run_model\nCaused by: KeyError: 'DikeIncrease 2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCaseError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'calling {} on {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             logger.debug(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(self, scenario, policy)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'calling {} on {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             logger.debug(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \"\"\"\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mmodel_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\dike_model\\dike_model_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, timestep, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogressive_height_and_costs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdikelist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplanning_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Willy\\Documents\\GitHub\\Model_based_decision_making\\EPA1361\\final assignment\\dike_model\\dike_model_function.py\u001b[0m in \u001b[0;36mprogressive_height_and_costs\u001b[1;34m(self, G, dikenodes, steps)\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DikeIncrease {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[1;31m# 1 Initialize fragility curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DikeIncrease 2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEMAError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-872bebed2f2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdike_model\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mreeevaluation_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mexperiments_reev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcomes_reev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreeevaluation_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mperform_experiments\u001b[1;34m(self, scenarios, policies, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, levers_sampling, callback)\u001b[0m\n\u001b[0;32m    173\u001b[0m                                    \u001b[0muncertainty_sampling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muncertainty_sampling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                                    \u001b[0mlevers_sampling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevers_sampling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                                    callback=callback)\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     def optimize(self, algorithm=EpsNSGAII, nfe=10000, searchover='levers',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mperform_experiments\u001b[1;34m(models, scenarios, policies, evaluator, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, levers_sampling, callback, return_callback)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m     \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscenarios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnr_of_exp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mevaluate_experiments\u001b[1;34m(self, scenarios, policies, callback)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mex_gen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0moutcomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0merrortype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             raise EMAError((\"exception in run_model\"\n\u001b[1;32m--> 102\u001b[1;33m                             \"\\nCaused by: {}: {}\".format(errortype, str(e))))\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0moutcomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutcomes_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEMAError\u001b[0m: exception in run_model\nCaused by: KeyError: 'DikeIncrease 2'"
     ]
    }
   ],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with SequentialEvaluator(dike_model) as evaluator:\n",
    "    reeevaluation_results = evaluator.perform_experiments(1000, policies=policies)\n",
    "    \n",
    "experiments_reev, outcomes_reev = reeevaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import save_results\n",
    "save_results((experiments_reev, outcomes_reev), f'../results/mordm_exp_2_1000.tar.gz')\n",
    "\n",
    "# experiments_reev, outcomes_reev = load_results('../results/mordm_exp_1000.tar.gz') \n",
    "# outcomes_reev_df = pd.DataFrame.from_dict(outcomes_reev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing both cells below we can see how we have 66 unique policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_reev.iloc[:,19:-3].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_reev['policy'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now only chose the policies that keep the number of deaths under the threshold in ALL scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_reev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_reev_df['policy']= experiments_reev['policy']\n",
    "policy_names = outcomes_reev_df.policy.unique()\n",
    "\n",
    "policies_of_interest = []\n",
    "for policy in policy_names:\n",
    "    policy_df = outcomes_reev_df[outcomes_reev_df['policy'] == policy]\n",
    "    policy_df_logical = policy_df['Expected Number of Deaths'] > (0.0001*3*5)\n",
    "    type(policy_df_logical)\n",
    "    if policy_df_logical.any():\n",
    "        continue\n",
    "    else:\n",
    "        policies_of_interest.append(policy)\n",
    "\n",
    "policies_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is no policy that obeys the threshold under all scenarios. We therefore calculate the robustness using the thresholds......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_reev_df_death= outcomes_reev_df[outcomes_reev_df['Expected Number of Deaths']<=(0.0001*3*5)]\n",
    "outcomes_reev_df_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Por ahora probamos sin evacuation costs y damage, que no estan especificados\n",
    "\n",
    "max_deaths = 0.0001\n",
    "max_rfr_costs = 1.1e9\n",
    "max_dike_costs = 3.04e8\n",
    "\n",
    "thresholds = {'Dike Investment Costs':max_dike_costs, 'RfR Investment Costs':max_rfr_costs, 'Expected Number of Deaths':max_deaths}\n",
    "\n",
    "overall_scores = {}\n",
    "for policy in experiments_reev.policy.unique():\n",
    "    logical = experiments_reev.policy == policy\n",
    "    scores = {}\n",
    "    for k, v in outcomes_reev.items():\n",
    "        try:\n",
    "            n = np.sum(v[logical]<=thresholds[k])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        scores[k] = n/1000 \n",
    "    overall_scores[policy] = scores\n",
    "        \n",
    "overall_scores = pd.DataFrame(overall_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall_scores_filtered = overall_scores[(overall_scores['Expected Number of Deaths'] >= 0.990) & (overall_scores['RfR Investment Costs'] == 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = parcoords.get_limits(overall_scores)\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(overall_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == 'SMALLER':\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "def costs(data):\n",
    "    return data[0]/1e3 # makes numbers nicer CAREFUL WITH UNITS\n",
    "    \n",
    "SMALLER = 'SMALLER'\n",
    "\n",
    "\n",
    "max_deaths = 0.0001\n",
    "max_rfr_costs = 1.1e9\n",
    "max_dike_costs = 3.04e8\n",
    "\n",
    "Expected_Annual_Damage = costs\n",
    "Dike_Investment_Costs = functools.partial(robustness, SMALLER, max_dike_costs)\n",
    "Expected_Number_of_Deaths = functools.partial(robustness, SMALLER, max_deaths)\n",
    "RfR_Investment_Costs = functools.partial(robustness, SMALLER, max_rfr_costs)\n",
    "Evacuation_Costs = costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "\n",
    "funcs = {'Expected Annual Damage': Expected_Annual_Damage,\n",
    "         'Dike Investment Costs': Dike_Investment_Costs,\n",
    "         'Expected Number of Deaths':Expected_Number_of_Deaths,\n",
    "         'RfR Investment Costs':RfR_Investment_Costs,       \n",
    "         'Evacuation Costs': Evacuation_Costs}\n",
    "\n",
    "total_scores = {}\n",
    "for policy in np.unique(experiments_reev['policy']):\n",
    "    scores = {}\n",
    "    logical = experiments_reev['policy'] == policy\n",
    "    \n",
    "    temp_outcomes = {k:v[logical] for k,v in outcomes_reev.items()}\n",
    "    \n",
    "    for k, v in temp_outcomes.items():\n",
    "        score = funcs[k](v)\n",
    "        scores[k] = score\n",
    "    total_scores[policy] = scores\n",
    "\n",
    "data = pd.DataFrame(total_scores).T#.reset_index(drop=True)\n",
    "limits = parcoords.get_limits(data)\n",
    "# limits.loc[0, :] = 0\n",
    "# limits.loc[1, :] = 1\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_death = data.sort_values(by=['Expected Number of Deaths']).tail(5)\n",
    "data_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_names = list(outcomes_reev.keys())\n",
    "n_policies = experiments_reev['policy'].nunique()\n",
    "n_experiments = len(experiments_reev)\n",
    "n_exp_pol = n_experiments/n_policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the regret we find the maximum value for each outcome under each policy with the same values for the uncertainties\n",
    "# Then, we calculate the regret and find the maximum regret to study which is the policy that has the lowest maximum regret\n",
    "final_regret = {}\n",
    "for outcome in outcomes_names:\n",
    "    policy_dict = {}\n",
    "\n",
    "    for i in range(1, n_policies+1):\n",
    "        # We first find the maximum value for each outcome under all policies\n",
    "        policy_row = outcomes_reev[outcome][int(n_exp_pol*(i-1)): int(n_exp_pol*i)]\n",
    "        policy_dict['policy'+f\"{i}\"] = policy_row\n",
    "    policy_df = pd.DataFrame.from_dict(policy_dict)\n",
    "    maxValuesObj = policy_df.max(axis=1)\n",
    "    regret_row = abs(policy_df.sub(maxValuesObj, axis='index'))\n",
    "    final_regret[outcome] = regret_row.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_df = pd.DataFrame.from_dict(final_regret)\n",
    "limits = parcoords.get_limits(regret_df)\n",
    "#limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(regret_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "for outcome in dike_model.outcomes:\n",
    "    policy_column = experiments_reev['policy']\n",
    "    \n",
    "    # create a DataFrame with all the relevent information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({outcome.name: outcomes_reev[outcome.name], \n",
    "                         \"policy\":experiments_reev['policy'],\n",
    "                         \"scenario\":experiments_reev['scenario']})\n",
    "    \n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # flatten the resulting hierarchical index resulting from \n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # we need to control the broadcasting. \n",
    "    # max returns a 1d vector across scenario id. By passing\n",
    "    # np.newaxis we ensure that the shape is the same as the data\n",
    "    # next we take the absolute value\n",
    "    #\n",
    "    # basically we take the difference of the maximum across \n",
    "    # the row and the actual values in the row\n",
    "    #\n",
    "    outcome_regret = (data.max(axis=1)[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regret = pd.DataFrame(max_regret)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,20))\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette()\n",
    "\n",
    "data = max_regret\n",
    "\n",
    "limits = parcoords.get_limits(data)\n",
    "#limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regret_filtered = max_regret.sort_values(by=['Expected Number of Deaths']).head(5)\n",
    "max_regret_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = parcoords.get_limits(max_regret_filtered)\n",
    "#limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(max_regret_filtered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = max_regret_filtered.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "max_regret_filtered_norm = pd.DataFrame(x_scaled, columns=max_regret_filtered.columns)\n",
    "\n",
    "\n",
    "limits = parcoords.get_limits(max_regret_filtered_norm)\n",
    "#limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(max_regret_filtered_norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "policy_regret = defaultdict(dict)\n",
    "for key, value in overall_regret.items():\n",
    "    for policy in value:\n",
    "        policy_regret[policy][key] = value[policy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates a 2 by 2 axes grid, with a shared X and Y axis\n",
    "# accross all plots\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10,10), \n",
    "                         sharey=True, sharex=True)\n",
    "\n",
    "# to ensure easy iteration over the axes grid, we turn it\n",
    "# into a list. Because there are four plots, I hard coded\n",
    "# this. \n",
    "axes = [axes[0,0], axes[0,1],        \n",
    "        axes[1,0],axes[1,1]]\n",
    "\n",
    "# zip allows us to zip together the list of axes and the list of \n",
    "# key value pairs return by items. If we iterate over this\n",
    "# it returns a tuple of length 2. The first item is the ax\n",
    "# the second items is the key value pair.\n",
    "for ax, (policy, regret) in zip(axes, policy_regret.items()):\n",
    "    data = pd.DataFrame(regret)\n",
    "\n",
    "    # we need to scale the regret to ensure fair visual\n",
    "    # comparison. We can do that by divding by the maximum regret\n",
    "    data = data/max_regret.max(axis=0)\n",
    "    sns.boxplot(data=data, ax=ax)\n",
    "    \n",
    "    # removes top and left hand black outline of axes\n",
    "    sns.despine()\n",
    "    \n",
    "    # ensure we know which policy the figure is for\n",
    "    ax.set_title(str(policy))\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#esto sirve para filtrar de outcomes\n",
    "outcomes_reev_logical = outcomes_reev['Expected Number of Deaths'] <= 0.0001\n",
    "experiments_reev_of_interest = experiments_reev.loc[outcomes_reev_logical]\n",
    "# outcomes_reev_of_interest_df = pd.DataFrame({k:v[outcomes_reev_logical] for k,v in outcomes_reev.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rfr_costs = 1.1e9\n",
    "max_dike_costs = 304e6\n",
    "outcomes_reev_logical_2 = outcomes_reev_of_interest_df['RfR Investment Costs'] <= max_rfr_costs\n",
    "outcomes_reev_of_interest_df = pd.DataFrame({k:v[outcomes_reev_logical_2] for k,v in outcomes_reev_of_interest_df.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_reev_of_interest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results of domain criterion\n",
    "limits = parcoords.get_limits(outcomes_reev_of_interest_df)\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(outcomes_reev_of_interest_df)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Re-evaluate candidate solutions under uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Policy\n",
    "\n",
    "policies = archive.drop([o.name for o in robustnes_functions], axis=1)\n",
    "policies_to_evaluate = []\n",
    "\n",
    "for i, policy in policies.iterrows():\n",
    "    policies_to_evaluate.append(Policy(\"moro {}\".format(i), **policy.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_scenarios = 1000\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            policies_to_evaluate)\n",
    "\n",
    "#start = time.time()\n",
    "#end = time.time()\n",
    "\n",
    "#print('Processing time:',(end-start)/60,'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import save_results\n",
    "\n",
    "save_results(results, 'MORO_reevaluation.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies.to_csv('moro polices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "experiments, outcomes = results\n",
    "\n",
    "overall_robustness = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    policy_robustness = {}\n",
    "\n",
    "    logical = experiments['policy'] == policy\n",
    "    \n",
    "    for outcome, values in outcomes.items():\n",
    "        values = values[logical]\n",
    "        policy_robustness[outcome] = robustness_funcs[outcome](values)\n",
    "    overall_robustness[policy] = policy_robustness\n",
    "overall_robustness = pd.DataFrame.from_dict(overall_robustness).T\n",
    "overall_robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = overall_robustness.loc[:, \n",
    "                              ['Expected Number of Deaths', 'Expected Annual Damage', 'Total Investment Costs']]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, :] = 0\n",
    "limits.loc[1, :] = 1\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
